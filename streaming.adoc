= Streaming in riff

== Current request-reply model ==

.square possible invocations in sequence
[plantuml, format="png"]
----
participant client
participant cluster
box "Pod 1" #LightBlue
	participant invoker
	participant function
end box

== First request-reply ==
client -> cluster : HTTP request [...] 'Host: square.default.example.com' [...] --data 8
cluster -> invoker : << activates pod >>
activate invoker
cluster -> invoker : << routes request >>
invoker -> function : << instanciates function once >>
activate function
invoker -> invoker : unmarshalls request payload
invoker -> function : invoke(fn,8)
function -> invoker : return 64
invoker -> invoker : marshalls response payload
invoker -> client : HTTP response with 64
== Second request-reply before scale-to-0 ==
client -> cluster : `HTTP request [...] 'Host: square.default.example.com' [...] --data 8
cluster -> invoker : << routes request >>
note right: the request could actually be routed to another pod instance instead or concurrently served to the same pod 
invoker -> invoker : unmarshalls payload
invoker -> function : invoke(fn,8)
function -> invoker : return 64
invoker -> invoker : marshalls response payload
invoker -> client : HTTP response with 64
...scale-to-zero timeout reached...
cluster -> invoker : <<scales pod down>>
invoker -> invoker : << shutdown >>
deactivate function
deactivate invoker
----

== Possible GRPC streaming model ==

.run-length encoding possible invocations in sequence
[plantuml, format="png"]
----
participant grpc_client
participant cluster
box "Pod 1" #LightBlue
	participant grpc_invoker
	participant function
end box


grpc_client -> cluster : GRPC request with 'Host: rle.default.example.com' [...] and payload "112221"
cluster -> grpc_invoker : << activates pod >>
activate grpc_invoker
cluster -> grpc_invoker : << routes request >>
grpc_invoker -> function : << instanciates function once >>
activate function
grpc_invoker -> grpc_invoker : unmarshalls request Protobuf payload
grpc_invoker -> function : invoke(fn, "112221")
function -> function : onNext("1")
function -> function : onNext("1")
function -> function : onNext("2")
function -> grpc_invoker : return Stream(Tuple("1", 2))
grpc_invoker -> grpc_invoker : marshalls data stream Protobuf payload
grpc_invoker ->  grpc_client : HTTP 2.0 data stream with GRPC payload ("1", 2)
function -> function : onNext("2")
function -> function : onNext("2")
function -> function : onNext("1")
function -> grpc_invoker : return Stream(Tuple("2", 3))
grpc_invoker -> grpc_invoker : marshalls data stream Protobuf payload
grpc_invoker ->  grpc_client : HTTP 2.0 data stream with GRPC payload ("2", 3)
function -> grpc_invoker : return Stream(Tuple("1", 1))
grpc_invoker -> grpc_invoker : marshalls data stream Protobuf payload
grpc_invoker ->  grpc_client : HTTP 2.0 data stream with GRPC payload ("1", 1)
...scale-to-zero timeout reached...
cluster -> grpc_invoker : <<scales pod down>>
grpc_invoker -> grpc_invoker : << shutdown >>
deactivate function
deactivate grpc_invoker
----